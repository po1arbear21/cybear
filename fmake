#!/usr/bin/env python

import argparse
import asyncio
import hashlib
import importlib
import json
import logging
import os
import re
import sys
from collections import namedtuple
from glob import glob
from types import new_class
from typing import (
    Any,
    Dict,
    List,
    Optional,
    Set,
    Union,
)

try:
    import matplotlib.pyplot as plt
    import networkx as nx
    import toml
except ModuleNotFoundError as e:
    sys.exit(
        f"A required package cannot be imported:\n\n\t{e}\n\nTry installing the package with 'pip install'."
    )


# All import regular expression for parsing .f90 source files.
# Your programs should be able to match these!
RE_INCLUDE = re.compile(r"m4_include\(\s*(.*)\)", re.MULTILINE)
RE_PROGRAM = re.compile(r"^program *(.*?)(?: *!|$)", re.MULTILINE)
RE_ENDPROGRAM = re.compile(r"^\s*end\s*program", re.MULTILINE)
RE_MODULE = re.compile(r"^module *(.*?)(?: *!|$)", re.MULTILINE)
RE_ENDMODULE = re.compile(r"^\s*end\s*(sub)?module", re.MULTILINE)
RE_SUBMODULE = re.compile(r"^submodule *\((.*)\) *(.*?)(?: *!|$)", re.MULTILINE)
RE_USE = re.compile(r"^\s*use(?:.*::)? *(.*?)(?: *,|$| *!)", re.MULTILINE)
RE_LIBRARY = re.compile(r"\!\!\!library *(.*)", re.MULTILINE)

# Separate out intel, gnu?
PROV_MODULES = (
    "iso_fortran_env",  # GNU, Intel
    "iso_c_binding",  # GNU, Intel
    "ieee_arithmetic",  # GNU, Intel
    "ieee_exceptions",  # Intel
    "ieee_features",  # Intel
    "lapack95",
    "blas95",
    "omp_lib",  # GNU, Intel OpenMP
    "omp_lib_kinds",  # GNU, Intel OpenMP
    "ifcore",  # Intel
    "ifport",  # Intel
)

STATUS_REQ = -999
STATUS_READY = 0
STATUS_QUEUE = 1
STATUS_FAILED = 2
STATUS_CHECK = 3
STATUS_BUILT = 4

COLORS = {
    "off": "\x1b[0m",
    "cmd": "\x1b[1;37m",
    "inp": "\x1b[1;32m",
    "out": "\x1b[1;36m",
    "bold": "\x1b[1m",  # Bold is a color?
    "bg_red": "\x1b[41m",
    "bg_mag": "\x1b[45m",
}

STATUS_STR = {
    0: f'{COLORS["bold"]}READY{COLORS["off"]}',
    1: f'{COLORS["bold"]}QUEUE{COLORS["off"]}',
    2: f'{COLORS["bold"]}FAILED{COLORS["off"]}',
    3: f'{COLORS["bold"]}CHECK{COLORS["off"]}',
    4: f'{COLORS["bold"]}BUILT{COLORS["off"]}',
    -1: f'{COLORS["bold"]}UNFINISHED DEPENDENDIES{COLORS["off"]}',
    -999: f'{COLORS["bold"]}UNRESOLCED REQUIREMENTS{COLORS["off"]}',
}

ICONS = {
    "check": "\x1b[32m\u2714\x1b[0m",
    "fail": "\x1b[31m\u2718\x1b[0m",
}


def make():
    global logger
    global config

    # Handle command line arguments
    parser = get_argparser()
    args = parser.parse_args()

    logging.addLevelName(5, "DETAILS")
    verbosity_log = {0: 0, 1: -10, 2: -15, 3: -16, 4: -17, 5: -18}
    log_level = 20 + args.quiet * 10 + verbosity_log[args.verbose]
    logging.basicConfig(level=log_level)
    logger = logging.getLogger("fmake")
    logger.debug(f"Initialized logger with level = {log_level}")

    if args.cmd == "clean":
        config = Configuration(args.config, args.dry_run, dir_only=True)

        def rmdir(pdir: str) -> None:
            logger.debug(f"Delete {pdir}")
            for root, dirs, files in os.walk(pdir):
                for file in files:
                    file_path = os.path.join(root, file)
                    os.remove(file_path)
                for dir in dirs:
                    dir_path = os.path.join(root, dir)
                    if len(os.listdir(dir_path)) > 0:
                        rmdir(dir_path)
                    else:
                        os.rmdir(dir_path)
            os.rmdir(pdir)

        if os.path.isdir(config.build_dir):
            rmdir(config.build_dir)
        else:
            logger.info("The build directory has already been cleaned up.")
        sys.exit(0)

    config = Configuration(args.config, args.dry_run)

    # Create dirs if nonexistent
    for key, dir in config.dirs.items():
        if key == "sources":
            continue
        if not os.path.isdir(dir):
            logger.info(f"Create non-existent directory '{dir}'")
            os.makedirs(dir)

    graph = Graph(args.targets)

    if args.cmd == "draw":
        graph.draw()
        sys.exit(0)

    # Load source files, sanitize path?
    src_files = glob(config.source_dir + "/**/*.f90", recursive=True) + glob(
        config.source_dir + "/**/*.c", recursive=True
    )

    # Find newly created files
    for src_file in src_files:
        graph.add_file(src_file)

    # Check and invalidate nodes
    graph.validate()

    # Compilation
    asyncio.run(graph.execute(args.workers, args.halt), debug=False)

    # Cache
    graph.write()


def get_argparser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(
        prog="fmake",
        description="\tAutomatic build tool for fortran projects using the fortran-basic repository as starting point.\n\tAllows for usage of the m4 macro processor in .f90 source files.\n\tThe dependencies of programs will be automatically analyzed and resolved when building a project.",
        formatter_class=argparse.RawTextHelpFormatter,
    )
    parser.add_argument(
        "cmd",
        nargs="?",
        default="build",
        help="Available options:\n  build  Builds the current project (DEFAULT)\n  draw   Draws the cached dependency tree with matplotlib\n  clean  Removes all build artifacts of the current configuration",
    )
    parser.add_argument(
        "targets",
        nargs="*",
        default=["all"],
        help="A list of targets to build. Defaults to all which builds all available targets.",
    )
    parser.add_argument(
        "--config",
        default="config.toml",
        help="Optional relative path to configuration file, defaults to 'config.toml'",
    )
    parser.add_argument(
        "-j",
        "--jobs",
        dest="workers",
        type=int,
        default=os.cpu_count(),
        help=f"Number of jobs to run simultaneously. Defaults to the number of CPUs in the system({os.cpu_count()}).",
    )
    parser.add_argument(
        "-v",
        "--verbose",
        action="count",
        default=0,
        help="Verbosity levels adjusting the logging level",
    )
    parser.add_argument(
        "-q",
        "--quiet",
        action="count",
        default=0,
        help="Suppress building information. '-q' supresses standard compile information and '-qq' also supresses warnings.",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        default=False,
        help="A dry run only uses m4 to parse the resulting f90 files. Compiling syntax-only, object files and linking the targets is replaced by sleep(1) commands.",
    )
    parser.add_argument(
        "-k",
        "--continue",
        dest="halt",
        action="store_false",
        default=True,
        help="Continue as far as possible after an error.",
    )

    return parser


class Cmd:
    """Command object which can be used to retrieve the arguments and pretty print them"""

    args: List[str]
    argd: List[str]

    def __init__(self, args: List[Union[str, List[str]]], argd: List[str]) -> None:
        """Arguments:
        - args  List of arguments
        - argd  Argument description, gives each argument a color"""

        self.args = []
        self.argd = []

        if len(args) != len(argd):
            logger.error(
                f"Cannot construct command from args '{args}' and description '{argd}"
            )
            sys.exit(1)

        for i in range(len(args)):
            if type(args[i]) is list:
                self.args += args[i]
                self.argd += [argd[i] for j in range(len(args[i]))]
            else:
                self.args.append(args[i])
                self.argd.append(argd[i])

    def get_args(self) -> List[str]:
        return self.args

    def print(self) -> str:
        col_args = [
            f"{COLORS[self.argd[i]]}{self.args[i]}{COLORS['off']}"
            for i in range(len(self.args))
        ]
        return " ".join(col_args)


class Configuration:
    """Handles configuration of the compilation process

    Attributes:
        - source_dir Base directory of all source files
        - uconf      User configuration dictionary from file
    """

    uconf: Dict[str, Dict[str, Any]]
    cconf: object

    dirs: Dict[str, str]
    project_dir: str
    source_dir: str
    build_dir: str
    f90_dir: str
    object_dir: str
    junk_dir: str

    m4_c: str
    m4_vars: Dict[str, Any]
    m4_flags: List[str]

    dry_run: bool

    def __init__(
        self, conf_name: Optional[str] = None, dry_run=False, dir_only=False
    ) -> None:
        """Initializes the configuration object

        Optionally pass a key for a configuration file in "config/"
        Special keys
            - list  Lists all
        """

        self.project_dir = os.getcwd()

        def get_abs(path: str) -> str:
            path = os.path.normpath(path)
            if os.path.isabs(path):
                return path
            return os.path.join(self.project_dir, path)

        self.dry_run = dry_run

        uconf_path = (
            get_abs(conf_name) if conf_name is not None else get_abs("config.toml")
        )
        self.project_dir = os.path.dirname(uconf_path)

        try:
            self.uconf = toml.load(uconf_path)
        except Exception as e:
            logger.error(
                f"Did you forget to configure your project with a toml configuration file?\n\tThe configuration file is expected at {uconf_path} otherwise use the --config option to specify the relative path.\n\tA typical configuration can be found at config/example.toml"
            )
            logger.error(f"Error when opening the configuration file: {e}")
            sys.exit(1)

        compiler = self.uconf["compilation"]["compiler"]
        mode = self.uconf["compilation"]["mode"]

        # Directories
        self.source_dir = (
            get_abs(self.uconf["project"]["sources"])
            if "sources" in self.uconf["project"]
            else get_abs("src")
        )
        self.build_dir = get_abs(
            os.path.join(self.uconf["compilation"]["build"], f"{compiler}-{mode}")
        )
        # ifort sometimes complains about missing modules
        # -> compile .mod files into sources dir,
        #    this will be searched before '-module'
        self.f90_dir = os.path.join(
            self.build_dir, "f90/"
        )  # Parsed sources and module files
        self.object_dir = os.path.join(self.build_dir, "obj/")  # Object files
        self.junk_dir = os.path.join(self.build_dir, "jnk/")  # Junk module files
        self.dirs = {
            "project": self.project_dir,
            "sources": self.source_dir,
            "build": self.build_dir,
            "f90": self.f90_dir,
            "object": self.object_dir,
            "junk": self.junk_dir,
        }
        logger.debug(f"Determined directories: {self.dirs}")

        if dir_only:
            return

        logger.debug(f"Found user configuration:\n{self.uconf}")

        intsize = self.uconf["options"]["INTSIZE"]
        if intsize not in [32, 64]:
            logger.error("INTSIZE must be 32 or 64")
            sys.exit(1)
        idxsize = self.uconf["options"]["IDXSIZE"]
        if idxsize not in [32, 64] or idxsize < intsize:
            logger.error("IDXSIZE must be 32 or 64 and greater or equal than INTSIZE")
            sys.exit(1)
        libraries = [
            lib for lib in self.uconf["libraries"] if self.uconf["libraries"][lib]
        ]

        try:
            w_bytecode = sys.dont_write_bytecode
            sys.dont_write_bytecode = True
            module = importlib.import_module(f"config.{compiler}")
            sys.dont_write_bytecode = w_bytecode
            self.cconf = module.Config(mode, intsize, idxsize, libraries)
            logger.debug(f"Compiler configuration: {self.cconf.__dict__}")
        except Exception as e:
            logger.error(f"Cannot load compiler configuration 'config.{compiler}': {e}")
            sys.exit(1)

        # M4 configuration as this is general
        self.m4_c = self.uconf["M4"]["M4"] if "M4" in self.uconf["M4"] else "m4"
        self.m4_flags = (
            self.uconf["M4"]["FLAGS"] if "FLAGS" in self.uconf["M4"] else ["-P", "-s"]
        )
        self.m4_vars = {}

        self.m4_vars["m4_intsize"] = intsize
        self.m4_vars["m4_idxsize"] = idxsize
        self.m4_vars["m4_projectdir"] = self.project_dir
        self.m4_vars["m4_intel"] = compiler == "intel"
        self.m4_vars["m4_gnu"] = compiler == "gnu"
        self.m4_vars["m4_debug"] = mode == "debug"

        for lib, use in self.uconf["libraries"].items():
            self.m4_vars["m4_" + lib.lower()] = use

        # Custom m4 variables will update all automatic variables
        if "VARS" in self.uconf["M4"]:
            self.m4_vars.update(self.uconf["M4"]["VARS"])

        for var, val in self.m4_vars.items():
            if type(val) is bool:
                if val:
                    self.m4_flags.append(f"-D{var}")
            else:
                self.m4_flags.append(f"-D{var}={val}")

        logger.debug(
            f"Configuration resulted in the definition of the following M4 variables:\n{self.m4_vars}\n"
        )
        logger.debug(f"The resulting M4 flags are:\n{' '.join(self.m4_flags)}")

    def m4(self, src: str) -> Cmd:
        return Cmd(
            [self.m4_c, self.m4_flags, f"-I{os.path.dirname(src)}", src],
            ["cmd", "off", "off", "inp"],
        )

    def fsyntax(self, anc: str) -> Cmd:
        if self.dry_run:
            return Cmd(["sleep", "1"], ["cmd", "inp"])

        f90 = os.path.join(self.f90_dir, anc.replace(".anc", ".f90"))
        return Cmd(
            [
                self.cconf.FC,
                self.cconf.FFLAGS,
                self.cconf.FINC,
                self.cconf.FMODULE,
                self.f90_dir,
                self.cconf.FSYNTAX_ONLY,
                "-c",
                f90,
            ],
            ["cmd", "off", "off", "off", "off", "off", "off", "inp"],
        )

    def fobject(self, obj: str) -> Cmd:
        if self.dry_run:
            return Cmd(["sleep", "1"], ["cmd", "inp"])

        f90 = os.path.join(self.f90_dir, obj.replace(".o", ".f90"))
        return Cmd(
            [
                self.cconf.FC,
                self.cconf.FFLAGS,
                self.cconf.FINC,
                "-I" + self.f90_dir,
                self.cconf.FMODULE,
                self.junk_dir,
                "-c",
                f90,
                "-o",
                os.path.join(self.object_dir, obj),
            ],
            ["cmd", "off", "off", "off", "off", "off", "off", "inp", "off", "out"],
        )

    def executable(
        self, program: str, objects: List[str], cobjects: List[str] = []
    ) -> Cmd:
        if self.dry_run:
            return Cmd(["sleep", "1"], ["cmd", "inp"])
        return Cmd(
            [
                self.cconf.FC,
                self.cconf.FFLAGS,
                self.cconf.LFLAGS,
                self.cconf.FINC,
                "-o",
                os.path.join(self.build_dir, program),
                objects,
                cobjects,
                self.cconf.LIBS,
            ],
            ["cmd", "off", "off", "off", "off", "out", "inp", "inp", "inp"],
        )

    def cc(self, c_object: str) -> Cmd:
        if self.dry_run:
            return Cmd(["sleep", "1"], ["cmd", "inp"])

        return Cmd(
            [
                self.cconf.CC,
                self.cconf.CFLAGS,
                self.cconf.CINC,
                "-c",
                os.path.join(self.f90_dir, c_object.replace(".c.o", ".c")),
                "-o",
                os.path.join(self.object_dir, c_object),
            ],
            ["cmd", "off", "off", "off", "inp", "off", "out"],
        )

    def library(
        self, library: str, objects: List[str], cobjects: List[str] = []
    ) -> Cmd:
        if self.dry_run:
            return Cmd(["sleep", "1"], ["cmd", "inp"])

        return Cmd(
            [
                "ar",
                "rcs",
                library,
                objects,
                cobjects,
            ],
            ["cmd", "cmd", "out", "inp", "inp"],
        )


Source = namedtuple("Source", ["path", "mtime", "includes", "checksum"])
F90 = namedtuple("F90", ["fname", "mods", "program", "library", "checksum"])


def parse_m4(src_file: str) -> Source:
    """Reads and parses a source file for its m4 dependencies. Additionally the checksum of the source file will be calculated.

    Returns a Source object storing the parsed information."""

    with open(src_file, mode="rt", encoding="utf-8") as file:
        src = file.read()

        # Calculate checksum, better way?
        h = hashlib.sha256()
        h.update(src.encode("utf-8"))
        checksum = h.hexdigest()

        includes = set(
            [
                os.path.normpath(os.path.join(os.path.dirname(src_file), m4_file))
                for m4_file in re.findall(RE_INCLUDE, src)
            ]
        )

    path = os.path.normpath(file.name)
    mtime = os.path.getmtime(path)
    logger.debug(
        f"Parsed m4 dependencies:\n  \u250C {COLORS['bold']}{path}{COLORS['off']}\n  \u251C\u2500\u2500 mtime: {mtime}\n  \u251C\u2500\u2500 checksum: {checksum}\n  \u251C\u2500\u2500 includes: {includes}"
    )

    return Source(path, mtime, includes, checksum)


def parse_f90(f90: str, src: str) -> F90:
    """Reads and parses a source file for its m4 dependencies. Additionally the checksum of the source file will be calculated.

    Returns a F90 object storing the parsed information."""

    mods: Dict = {}

    h = hashlib.sha256()
    h.update(src.encode("utf-8"))
    checksum = h.hexdigest()

    # Should file be packed as library?
    lib_match = re.search(RE_LIBRARY, src)
    library = None
    if lib_match:
        # Error checking?
        library = lib_match.group(1).lower()

    pro_match = re.search(RE_PROGRAM, src)
    program = None
    if pro_match:
        start = pro_match.start()
        end_match = re.search(RE_ENDPROGRAM, src)
        end = end_match.end() if end_match else len(src)
        if not end_match:
            logger.error(f"Found no 'end program' statement in {f90}")
        program = pro_match.group(1).lower()
        mods[program] = {
            "type": "program",
            "name": program,
            "dependencies": tuple(
                filter(
                    lambda dep: dep not in PROV_MODULES,
                    re.findall(RE_USE, src[start:end]),
                )
            ),
        }
        src = src[:start] + src[end:]

    # Iterate over module and submodule sources
    module = re.search(RE_MODULE, src)
    mod_start = module.start() if module else len(src)
    submodule = re.search(RE_SUBMODULE, src)
    smod_start = submodule.start() if submodule else len(src)

    while module or submodule:
        end_match = re.search(RE_ENDMODULE, src)
        end = end_match.end() if end_match else len(src)

        if mod_start < smod_start and module:
            # Parse module
            name = module.group(1)
            mods[name] = {
                "type": "mod",
                "name": name,
                "dependencies": tuple(
                    filter(
                        lambda dep: dep not in PROV_MODULES,
                        re.findall(RE_USE, src[mod_start:end]),
                    )
                ),
            }
            src = src[:mod_start] + src[end:]

        elif smod_start < mod_start and submodule:
            # Parse submodule
            name = submodule.group(2)
            mods[name] = {
                "type": "smod",
                "name": name,
                "parent": submodule.group(1),
                "dependencies": tuple(
                    filter(
                        lambda dep: dep not in PROV_MODULES,
                        re.findall(RE_USE, src[smod_start:end]),
                    )
                ),
            }
            src = src[:smod_start] + src[end:]
        else:
            logger.error(
                f"Invalid module/submodule matches in {f90}: {module.group() if module else None}, {submodule.group() if submodule else None}"
            )

        module = re.search(RE_MODULE, src)
        mod_start = module.start() if module else len(src)
        submodule = re.search(RE_SUBMODULE, src)
        smod_start = submodule.start() if submodule else len(src)

    logger.debug(
        f"Parsed .f90 file:\n  \u250C {COLORS['bold']}{f90}{COLORS['off']}\n  \u251C\u2500\u2500 checksum: {checksum}\n  \u251C\u2500\u2500 program: {program}\n  \u251C\u2500\u2500 library: {library}\n  \u2514\u2500\u2500 modules: {mods}"
    )

    return F90(f90, mods, program, library, checksum)


class Graph:
    """Module dependency graph containing all programs, libraries, modules and submodules.
    Wraps around the package "networkx".


    Attributes:
        - programs List of dependency trees for each program
    """

    graph: nx.DiGraph
    target_layer: int

    halt: bool
    targets: Set[str]
    required: List[str]
    smods: Dict[str, List[str]]

    rule_check: Dict[str, bool]

    warnings: List[str]
    errors: List[str]

    def __init__(self, req_targets: List[str]) -> None:
        self.fname = f"{config.uconf['project']['name'].lower()}-depgraph.json"
        self.target_layer = 200
        self.required = req_targets
        self.rule_check = {}

        self.warnings = []
        self.errors = []

        try:
            with open(os.path.join(config.build_dir, self.fname), "r") as file:
                self.graph = nx.node_link_graph(json.load(file))
                self.status = self.graph.graph["status"]
                logger.info(
                    f"Loaded from dependency graph from cache {file.name} with status {STATUS_STR[self.status]}"
                )

        except Exception as e:
            logger.info(f"Cannot find/load dependency graph: {e}")
            self.graph = nx.DiGraph()
            self.graph.graph["rules"] = {}
            self.status = STATUS_READY

        self.sync_targets()
        self.sync_smods()

    def add_file(self, src_file: str) -> None:
        """Adds a new src file to the dependency if it does not exist"""

        if src_file in self.graph.nodes:
            return

        self.graph.add_node(
            src_file,
            type="src",
            checksum="",
            mtime=0.0,
            status=STATUS_BUILT,
            target=None,
        )

    def validate(self) -> None:
        """Checks which nodes need to be executed"""

        valid: bool

        logger.debug("Start validating existing nodes...")
        self.status = STATUS_CHECK

        # Set checkable nodes
        for n, data in self.graph.nodes(data=True):
            if data is None:
                continue
            if data["status"] in [STATUS_QUEUE, STATUS_CHECK]:
                # Invalid behavior
                logger.error(
                    f"Undefined status {data['status']} of node {n} when validating"
                )
                sys.exit(1)
            # TODO: Failed just goes into renew_status()
            elif data["status"] == STATUS_FAILED:
                self.graph.nodes[n]["status"] = STATUS_READY
            elif data["status"] == STATUS_BUILT:
                self.graph.nodes[n]["status"] = STATUS_CHECK
                logger.log(5, f"  marking node {n} to check validity")
            else:
                logger.log(
                    5,
                    f"  Invalid node {n} keeps status {self.graph.nodes[n]['status']}",
                )

        self.check_rules()

        logger.debug("Check individual nodes...")

        for n in tuple(self.graph.nodes):
            if n not in self.graph.nodes:
                logger.debug(f"Node {n} has been deleted while validating")
                continue
            logger.log(5, f"  check {n} ({self.graph.nodes[n]['status']})")
            if self.graph.nodes[n]["status"] != STATUS_CHECK:
                continue

            type = self.graph.nodes[n]["type"]
            if type == "src":
                valid = self.check_src(n)
            elif type == "inc":
                valid = self.check_inc(n)
            elif type in ["f90", "anc", "obj", "tar", "cobj"]:
                valid = self.check_rule(n)
            else:
                valid = True
                self.graph.nodes[n]["status"] = STATUS_BUILT

            logger.debug(
                f"The checked node {n} is {'valid' if valid else 'invalid'}. The status has been set to {self.graph.nodes[n]['status']}{' and the descendants will be invalidated.' if not valid else '.'}"
            )
            if self.graph.nodes[n]["status"] == STATUS_CHECK:
                logger.error(f"The status of node {n} has remained at STATUS_CHECK!")
                sys.exit(1)

            if not valid:
                self.invalidate(n)

        # TODO: Renewing status required?
        # FIXME: Confirmation can be removed
        for n, status in self.graph.nodes(data="status"):
            if status == STATUS_CHECK:
                logger.error(f"Node {n} remained at STATUS_CHECK!")
            if status < STATUS_BUILT:
                old_stat = self.graph.nodes[n]["status"]
                self.renew_status(n)
                new_stat = self.graph.nodes[n]["status"]
                if old_stat != new_stat:
                    logger.warning(
                        f"Status changed unexpectedly after validation run. node {n}: {old_stat} -> {new_stat}"
                    )

    async def execute(self, num_workers: int, halt: bool) -> None:
        """Executes the compilation process by first checking the leaves (src and inc) for changes. After that
        nodes that are ready for execution will be queued and executed by the defined number of workers asynchronously.
        """

        queue: asyncio.Queue
        queue = asyncio.Queue()

        self.halt = halt

        # TODO: Queue starting point???
        logger.debug("Adding to execution queue:")
        for n in self.graph.nodes:
            status = self.graph.nodes[n]["status"]
            type = self.graph.nodes[n]["type"]
            if type in ["f90", "c"] and status == STATUS_READY:
                logger.debug(f" + {n} (f90/c, ready)")
                queue.put_nowait(n)
                self.graph.nodes[n]["status"] = STATUS_QUEUE
            elif type in ["src", "inc", "req"]:
                # TODO: Why are 'req' nodes queueable?
                continue
            elif self.is_queueable(n):
                logger.debug(f" + {n} (queueable)")
                queue.put_nowait(n)
                self.graph.nodes[n]["status"] = STATUS_QUEUE
            else:
                logger.log(5, f" / {n} (not queuable)")

        if queue.empty():
            logger.info("Nothing to do ...")

        self.status = STATUS_QUEUE

        tasks = []
        for _ in range(num_workers):
            task = asyncio.create_task(self.worker(queue))
            tasks.append(task)

        await queue.join()

        for task in tasks:
            task.cancel()
        await asyncio.gather(*tasks, return_exceptions=True)

        for n in self.graph:
            if self.graph.nodes[n]["status"] == STATUS_QUEUE:
                logger.error(
                    f"Node {n} still has queue status after completion of all tasks."
                )

        for warning in self.warnings:
            logger.warning(warning)
        for error in self.errors:
            logger.error(error)

        def find_problems(node: str) -> Set[str]:
            problems: Set[str]
            problems = set()
            for pred in self.graph.predecessors(node):
                status = self.graph.nodes[pred]["status"]
                if status in [STATUS_FAILED, STATUS_REQ]:
                    problems.add(pred)
                if status < STATUS_READY:
                    problems.update(find_problems(pred))
            return problems

        # Check if all required targets are built.
        summary = "Target summary:"
        self.status = STATUS_BUILT
        for target in self.targets:
            status = self.graph.nodes[target]["status"]
            if status == STATUS_BUILT:
                summary += f"\n  - {target}: {ICONS['check']}"
            elif status == STATUS_FAILED:
                summary += f"\n  - {target}: {ICONS['fail']}"
            elif status in [STATUS_READY, STATUS_QUEUE, STATUS_CHECK]:
                summary += f"\n  - {target}: unexpected status {status}"
            else:
                # find 'problems'
                problem_msg = {
                    -999: "unprovided required module ",
                    STATUS_FAILED: "failed execution of ",
                }
                summary += f"\n  - {target}: found problems {[problem_msg[self.graph.nodes[n]['status']] + n for n in find_problems(target)]}"

            self.status = min(self.status, status)
        self.status = max(self.status, STATUS_FAILED)
        if self.status < 0:
            summary += f"\n => status {STATUS_STR[-1]}"
        else:
            summary += f"\n => status {STATUS_STR[self.status]}"
        logger.info(summary)

    def check_rules(self) -> None:
        """Compare current with cached build rules and invalidate valid nodes with outdated rules."""

        m4_rule = " ".join(config.m4("/").get_args())
        logger.log(5, f"Got comparison m4 rule: {m4_rule}")

        rules = {
            "m4": m4_rule,
            "fsyntax": " ".join(config.fsyntax("xyz.anc").get_args()),
            "fobject": " ".join(config.fobject("xyz.obj").get_args()),
            "executable": " ".join(
                config.executable("xyz", ["obj1", "obj2"], ["cobj"]).get_args()
            ),
            "library": " ".join(
                config.library("xyz", ["obj1", "obj2"], ["cobj"]).get_args()
            ),
            "cc": " ".join(config.cc("cobj.c.o").get_args()),
        }

        rule_types = {
            "m4": "f90",
            "fsyntax": "anc",
            "fobject": "obj",
            "executable": "tar",
            "library": "tar.a",
            "cc": "cobj",
        }

        for key in rules:
            if key not in self.graph.graph["rules"]:
                self.graph.graph["rules"][key] = rules[key]
                self.rule_check[rule_types[key]] = False
                logger.log(
                    5, f"Build rule {key} for {rule_types[key]} has not been cached."
                )
            elif rules[key] != self.graph.graph["rules"][key]:
                self.graph.graph["rules"][key] = rules[key]
                self.rule_check[rule_types[key]] = False
                logger.log(
                    5,
                    f"Build rule {key} for {rule_types[key]} has changed:\n  {self.graph.graph['rules'][key]}\n  \u2193\n  {rules[key]}.",
                )
            else:
                self.rule_check[rule_types[key]] = True
                logger.log(5, f"Build rule {key} for {rule_types[key]} is valid.")

    def sync_targets(self) -> None:
        """Updates self.targets based on the existing targets in the graph and the required build targets."""

        targets = [n for n, type in self.graph.nodes(data="type") if type == "tar"]

        if "all" in self.required:
            self.targets = set(targets)
            return

        self.targets = set()
        for target in self.required:
            if target not in targets:
                continue
            self.targets.add(target)

    def sync_smods(self) -> None:
        """Adds submodules to track them and their parents outside of the graph."""
        smods: Dict[str, List[str]]
        smods = {}

        for n, data in self.graph.nodes(data=True):
            if data["type"] != "smod":
                continue
            if data["parent"] not in smods:
                smods[data["parent"]] = []

            smods[data["parent"]].append(next(self.graph.predecessors(n)))
        self.smods = smods

    def renew_status(self, node: str) -> None:
        """Updates the status of the node, valid nodes will be invalidated."""

        # Are there other statuses which need to be untouchable?
        if self.graph.nodes[node]["type"] == "req":
            logger.error(f"Cannot renew status of required module {node}!")
            return

        status = 0
        for pred in self.graph.predecessors(node):
            if self.graph.nodes[pred]["status"] < STATUS_CHECK:
                status -= 1
        self.graph.nodes[node]["status"] = status

    def invalidate(self, node: str) -> None:
        """Invalidate a node or a type of nodes and update their descendants accordingly."""

        if self.status != STATUS_CHECK:
            logger.error(f"Cannot invalidate in status {self.status}")
            sys.exit(1)

        invalidated = set()
        for desc in nx.descendants(self.graph, node):
            if self.graph.nodes[desc]["status"] == STATUS_QUEUE:
                logger.warning(
                    f"Invalidating from {node} will overwrite the queue status of {desc}"
                )
            self.graph.nodes[desc]["status"] = STATUS_READY
        for desc in nx.descendants(self.graph, node):
            self.renew_status(desc)
            invalidated.add((desc, self.graph.nodes[desc]["status"]))
        logger.log(5, f"Invalidated from {node}: {invalidated}")

    def check_src(self, src: str) -> bool:
        if not os.path.isfile(src):
            self.del_file(src)
            return True

        mtime = os.path.getmtime(src)
        if mtime <= self.graph.nodes[src]["mtime"]:
            logger.log(
                5,
                f"Source file {src} is valid (current mtime: {mtime}, stored mtime: {self.graph.nodes[src]['mtime']})",
            )
            self.graph.nodes[src]["status"] = STATUS_BUILT
            return True

        source = parse_m4(src)

        if source.checksum == self.graph.nodes[src]["checksum"]:
            logger.log(5, f"Source file {src} is valid (checksum)")
            self.graph.nodes[src]["mtime"] = mtime
            self.graph.nodes[src]["status"] = STATUS_BUILT
            return True

        self.del_file(src)
        logger.log(5, f"Source file {src} is invalid.")

        if src.endswith(".c"):
            self.new_cfile(source)
            return False

        self.new_ffile(source)
        return False

    def check_inc(self, inc: str) -> bool:
        mtime = os.path.getmtime(inc)
        self.graph.nodes[inc]["status"] = STATUS_BUILT
        if mtime > self.graph.nodes[inc]["mtime"]:
            logger.log(
                5,
                f"Include file {inc} is invalid (current mtime: {mtime}, stored mtime: {self.graph.nodes[inc]['mtime']}",
            )
            self.graph.nodes[inc]["mtime"] = mtime
            return False
        return True

    def check_rule(self, node: str) -> bool:
        """Compare current with cached build rules and invalidate valid nodes with outdated rules."""

        if node.endswith(".a"):
            ret = self.rule_check["tar.a"]
        else:
            ret = self.rule_check[self.graph.nodes[node]["type"]]

        self.graph.nodes[node]["status"] = STATUS_BUILT if ret else STATUS_READY
        return ret

    def new_ffile(self, source: Source) -> None:
        """Inserts nodes for a new fortran source file to the graph (src, f90 and m4 dependencies)"""

        fname = os.path.basename(source.path)
        self.graph.add_node(
            source.path,
            type="src",
            checksum=source.checksum,
            mtime=source.mtime,
            status=STATUS_BUILT,
            target=None,
        )
        self.graph.add_node(
            fname,
            type="f90",
            src=source.path,
            status=STATUS_READY,
            target=None,
        )
        self.graph.add_edge(source.path, fname)

        # Can new include files be set to STATUS_BUILT?
        for inc in source.includes:
            if inc not in self.graph:
                mtime = os.path.getmtime(inc)
                self.graph.add_node(inc, type="inc", mtime=mtime, status=STATUS_BUILT)
            self.graph.add_edge(inc, fname)

    def new_cfile(self, source: Source) -> None:
        """Inserts nodes for a new c source file into the graph(src, c and cobj node).
        Connects the c object file to all targets."""

        fname = os.path.basename(source.path)
        cobj = fname + ".o"

        self.graph.add_node(
            source.path,
            type="src",
            checksum=source.checksum,
            mtime=source.mtime,
            status=STATUS_BUILT,
            target=None,
        )
        self.graph.add_node(
            fname,
            type="c",
            src=source.path,
            status=STATUS_READY,
            target=None,
        )
        self.graph.add_node(
            cobj,
            type="cobj",
            status=-1,
        )
        self.graph.add_edge(source.path, fname)
        self.graph.add_edge(fname, cobj)

        targets = [n for n, type in self.graph.nodes(data="type") if type == "tar"]
        for target in targets:
            self.graph.add_edge(cobj, target)

    def is_queueable(self, node: str) -> bool:
        """Can <node> be added to the queue?
        Conditions:
            - status must be STATUS_READY
            - must have a path to a target
        """
        if self.graph.nodes[node]["status"] != STATUS_READY:
            return False

        for target in self.targets:
            if node == target:
                return True
            if target in nx.descendants(self.graph, node):
                return True
        return False

    async def worker(self, queue: asyncio.Queue) -> None:
        """A single worker takes nodes from the queue, executes them and possibly adds new nodes."""

        while self.status == STATUS_QUEUE or self.halt is False:
            node = await queue.get()
            await self.execute_node(node)

            if self.status == STATUS_QUEUE or self.halt is False:
                for n in self.propagate(node):
                    queue.put_nowait(n)
                    self.graph.nodes[n]["status"] = STATUS_QUEUE

                queue.task_done()
                continue

            queue.task_done()
            # Clear queue on error if halt is enabled
            while not queue.empty():
                n = queue.get_nowait()
                self.graph.nodes[n]["status"] = STATUS_READY
                queue.task_done()

    def propagate(self, node: str) -> Set[str]:
        """Finds a set of nodes which can be queued."""

        type = self.graph.nodes[node]["type"]
        debug_msg = f"Find queue propagation for\n  \u250C {node}"

        if type in ["inc", "smod", "tar"]:
            logger.log(5, f"{debug_msg}\n  \u2514 none")
            return set()
        elif type == "src":
            executables = set()
            succ = next(self.graph.successors(node))
            if self.graph.nodes[succ]["status"] < STATUS_BUILT:
                executables.add(succ)

            debug_msg += f"\n  \u2514 resulting in {executables}"
            logger.log(5, debug_msg)
            return executables
        elif type in ["anc", "mod", "c", "obj", "cobj"]:
            executables = set()
            for n in self.graph.successors(node):
                debug_msg += (
                    f"\n  \u251C\u2500 {n}: status = {self.graph.nodes[n]['status']}"
                )
                if self.is_queueable(n):
                    executables.add(n)
            debug_msg += f"\n  \u2514 resulting in {executables}"
            logger.log(5, debug_msg)
            return executables
        elif type != "f90":
            logger.error(f"Got undefined type {type} when propagating the queue.")
            sys.exit(1)

        # F90 files require additional care after changed targets
        executables = set()

        anc = next(self.graph.successors(node))
        debug_msg += (
            f"\n  \u251C\u2500 {anc}: status = {self.graph.nodes[anc]['status']}"
        )
        if self.is_queueable(anc):
            executables.add(anc)

        # Fulfilling module dependencies may result giving the dependencies of the
        # anchor a path to a required target.
        if not self.targets.isdisjoint(nx.descendants(self.graph, node)):
            debug_msg += f"\n  \u251C new nodes with possible path"
            for n in nx.ancestors(self.graph, anc):
                debug_msg += f"\n  \u251C\u2500\u2500 {n}: status = {self.graph.nodes[n]['status']}"
                if self.is_queueable(n):
                    executables.add(n)

        # New target => nodes ready for execution now possibly have a path to the new
        # target
        target = self.graph.nodes[node]["target"]
        if not target:
            debug_msg += f"\n  \u2514 resulting in {executables}"
            logger.log(5, debug_msg)
            return executables
        if target not in self.targets:
            debug_msg += f"\n  \u2514 resulting in {executables}"
            logger.log(5, debug_msg)
            return executables

        debug_msg += "\n  \u251C new target {target}"
        for n in self.graph.nodes:
            if self.graph.nodes[n]["type"] != "anc":
                continue
            debug_msg += (
                f"\n  \u251C\u2500\u2500 {n}: status = {self.graph.nodes[n]['status']}"
            )
            if self.is_queueable(n):
                executables.add(n)

        debug_msg += f"\n  \u2514 resulting in {executables}"
        logger.log(5, debug_msg)
        return executables

    async def execute_node(self, node: str):
        """Execute a node"""

        type = self.graph.nodes[node]["type"]

        if self.graph.nodes[node]["status"] != STATUS_QUEUE:
            logger.error(
                f"Node {node} scheduled for execution has status {self.graph.nodes[node]['status']}"
            )
            return

        # Can Python call async functions dynamically?
        ret = 1
        if type == "f90":
            ret = await self.execute_f90(node)
        elif type == "c":
            src = self.graph.nodes[node]["src"]
            ret = await self.execute_cmd(
                node, Cmd(["cp", src, config.f90_dir], ["cmd", "inp", "out"])
            )
        elif type == "anc":
            ret = await self.execute_cmd(node, config.fsyntax(node))
            # Move possible .i90 file into build dir
            ifile = os.path.splitext(os.path.basename(node))[0] + ".i90"
            if os.path.exists(os.path.join(os.getcwd(), ifile)):
                args = ["mv", ifile, config.f90_dir]
                process = await asyncio.create_subprocess_exec(*args)
                await process.wait()
        elif type in ["mod", "smod"]:
            ret = 0
        elif type == "obj":
            ret = await self.execute_cmd(node, config.fobject(node))
        elif type == "cobj":
            ret = await self.execute_cmd(node, config.cc(node))
        elif type == "tar":
            objects = [
                os.path.join(config.object_dir, n)
                for n in self.graph.predecessors(node)
                if self.graph.nodes[n]["type"] == "obj"
            ]
            cobjects = [
                os.path.join(config.object_dir, n)
                for n in self.graph.predecessors(node)
                if self.graph.nodes[n]["type"] == "cobj"
            ]
            cmd = (
                config.library(node, objects, cobjects=cobjects)
                if node.endswith(".a")
                else config.executable(node, objects, cobjects=cobjects)
            )
            ret = await self.execute_cmd(node, cmd)
        elif type in ["src", "inc"]:
            logger.error(
                f"Retrived invaid node type {node} ({self.graph.nodes[node]['type']}) from queue!"
            )
        else:
            logger.error(f"Invalid type while executing: {type}")

        if ret != 0:
            self.graph.nodes[node]["status"] = STATUS_FAILED
            self.status = STATUS_FAILED
            return

        self.graph.nodes[node]["status"] = STATUS_BUILT

        if self.status == STATUS_CHECK:
            return

        for succ in self.graph.successors(node):
            self.graph.nodes[succ]["status"] += 1

    async def execute_cmd(self, node: str, cmd: Cmd) -> int:
        process = await asyncio.create_subprocess_exec(
            *cmd.get_args(),
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
        )

        logger.info(f"Start execution of node {node}:\n\n{cmd.print()}\n")

        stdout, stderr = await process.communicate()
        ret = process.returncode

        logger.debug(
            f"Executed node {node}:\n\n{cmd.print()}\n\n{stdout.decode()}\n\n{stderr.decode()}"
        )

        if ret == 0:
            logger.info(f"{ICONS['check']} {node}")

            # Warnings
            if stderr:
                self.warnings.append(
                    f"{COLORS['bg_mag']}Execution of node {node} resulted in warnings:{COLORS['off']}\n\n{cmd.print()}\n\n{stderr.decode()}"
                )
            return ret

        logger.error(f"{ICONS['fail']} {node}")
        self.errors.append(
            f"{COLORS['bg_red']}Execution of node {node} resulted in errors ({ret}):{COLORS['off']}\n\n{cmd.print()}\n\n{stderr.decode()}"
        )

        return ret

    async def execute_f90(self, f90: str) -> int:
        fname = os.path.join(config.f90_dir, f90)
        with open(fname, "w") as m4_file:
            src = self.graph.nodes[f90]["src"]

            cmd = config.m4(src)
            process = await asyncio.create_subprocess_exec(
                *cmd.get_args(),
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
            )

            logger.info(f"Start execution of node {f90}:\n{cmd.print()}")

            stdout, stderr = await process.communicate()
            ret = process.returncode

            logger.debug(
                f"Executed node {f90}:\n{cmd.print()}\n\n{stdout.decode()}\n\n{stderr.decode()}"
            )

            if ret == 0:
                logger.info(f"{ICONS['check']} {f90}")

                fsrc = stdout.decode()
                m4_file.write(fsrc)
                self.add_dep(parse_f90(f90, fsrc))

                # Warnings
                if stderr:
                    self.warnings.append(
                        f"Execution of node {f90} resulted in warnings:\n\n{cmd.print()}\n\n{stderr.decode()}"
                    )
                return ret

            logger.error(f"{ICONS['fail']} {f90}")
            self.errors.append(
                f"Execution of node {f90} resulted in errors ({ret}):\n\n{cmd.print()}\n\n{stderr.decode()}"
            )

            return ret

    def del_file(self, src_file: str) -> None:
        """Deletes a source file (C or Fortran) from the dependency graph"""

        self.graph.remove_node(src_file)

        fname = os.path.basename(src_file)
        if fname not in self.graph.nodes:
            return

        if src_file.endswith(".c"):
            cobj = fname + ".o"
            self.graph.remove_node(fname)
            self.graph.remove_node(cobj)
            return

        target = self.graph.nodes[fname]["target"]
        name = os.path.splitext(fname)[0]
        self.graph.remove_node(fname)

        sync_smods = False
        modules = tuple(self.graph.successors(name + ".anc"))
        for mod in modules:
            if self.graph.nodes[mod]["type"] == "obj":
                continue

            if self.graph.nodes[mod]["type"] == "smod":
                sync_smods = True

            has_dep = False
            for _ in self.graph.successors(mod):
                has_dep = True
                break

            if not has_dep:
                self.graph.remove_node(mod)
            else:
                self.graph.nodes[mod]["type"] = "req"
                self.graph.nodes[mod]["status"] = STATUS_REQ

                logger.debug(f"Replaced {mod} by a required node, invalidate!")
                self.invalidate(mod)

        self.graph.remove_node(name + ".anc")
        self.graph.remove_node(name + ".o")

        if sync_smods:
            self.sync_smods()

        if target:
            self.graph.remove_node(target)
            self.sync_targets()

    def add_dep(self, f90: F90):
        debug_msg = f"Resolving dependencies in the dependency graph:\n  \u250C {COLORS['bold']}{f90.fname}{COLORS['off']}"
        name = os.path.splitext(f90.fname)[0]

        anc = name + ".anc"
        self.graph.add_node(
            anc,
            type="anc",
            status=-1,
        )
        self.graph.add_edge(f90.fname, anc)

        smod_parents = set()

        # Dependencies: require module or find existing one
        for mod in f90.mods:
            for dep in f90.mods[mod]["dependencies"]:
                if dep not in self.graph:
                    self.graph.add_node(dep, type="req", status=STATUS_REQ)
                    debug_msg += f"\n  \u251C\u2500\u2500 required dependency {dep}"
                else:
                    debug_msg += f"\n  \u251C\u2500\u2500 added dependency {dep}"
                self.graph.add_edge(dep, anc)

            # Submodules need the parents mod file to compile correctly
            if f90.mods[mod]["type"] == "smod":
                parent = f90.mods[mod]["parent"]
                smod_parents.add(parent)
                if parent not in self.graph:
                    self.graph.add_node(parent, type="req", status=STATUS_REQ)
                self.graph.add_edge(parent, anc)
                debug_msg += f"\n  \u251C\u2500\u2500 added parent module {parent} of {mod} as dependency"

        self.renew_status(anc)
        debug_msg += f"\n  \u251C\u2500\u2500 added anchor node {anc} with status = {self.graph.nodes[anc]['status']}"

        sync_smods = False
        for mod in f90.mods:
            info = f90.mods[mod]
            if info["type"] not in ["mod", "smod"]:
                continue

            if info["type"] == "smod":
                sync_smods = True

            # Fulfill dependency
            if mod in self.graph:
                self.graph.nodes[mod]["type"] = "mod"
                self.graph.nodes[mod]["status"] = -1
                self.graph.add_edge(anc, mod)

                debug_msg += f"\n  \u251C\u2500\u2500 fulfill requirement {mod}"

            # Create
            else:
                self.graph.add_node(
                    mod,
                    type=info["type"],
                    status=-1,
                )

                if info["type"] == "smod":
                    self.graph.nodes[mod]["parent"] = info["parent"]

                self.graph.add_edge(anc, mod)
                debug_msg += f"\n  \u251C\u2500\u2500 added new module {mod}"

        try:
            cycle = nx.find_cycle(self.graph, anc, orientation="original")
            logger.error(f"Found cyclic dependency: {cycle}")
            sys.exit(1)
        except nx.NetworkXNoCycle:
            pass

        obj = name + ".o"
        self.graph.add_node(
            obj,
            type="obj",
            status=-1,
        )
        self.graph.add_edge(anc, obj)
        debug_msg += f"\n  \u251C\u2500\u2500 added object {obj}"

        targets = [n for n, type in self.graph.nodes(data="type") if type == "tar"]
        if sync_smods:
            self.sync_smods()

        for target in targets:
            ancs = nx.ancestors(self.graph, target)
            if anc in ancs or not ancs.isdisjoint(smod_parents):
                self.graph.add_edge(obj, target)
                debug_msg += (
                    f"\n  \u251C\u2500\u2500 link object file {obj} to target {target}"
                )

                # Check if all ancestors objects are linked to target
                for n in nx.ancestors(self.graph, anc):
                    # Add smod objects
                    if n in self.smods.keys():
                        for sanc in self.smods[n]:
                            sobj = sanc.replace(".anc", ".o")
                            if not self.graph.has_edge(sobj, target):
                                self.graph.add_edge(sobj, target)
                                debug_msg += f"\n  \u251C\u2500\u2500\u2500\u2500 link submodule object {sobj} to target"
                    if self.graph.nodes[n]["type"] != "anc":
                        continue
                    if not self.graph.has_edge(n.replace(".anc", ".o"), target):
                        self.graph.add_edge(n.replace(".anc", ".o"), target)
                        debug_msg += f"\n  \u251C\u2500\u2500\u2500\u2500 link object {n.replace('.anc', '.o')}"
                self.renew_status(target)

        if f90.program:
            program = f90.program
            src = self.graph.nodes[f90.fname]["src"]
            self.graph.add_node(
                program,
                type="tar",
                library=False,
                src=src,
                anc=anc,
                status=-1,
            )
            self.graph.nodes[f90.fname]["target"] = program

            self.graph.add_edge(obj, program)

            debug_msg += f"\n  \u251C\u2500\u2500 add new program {program}"

            # Add old object files
            for n in nx.ancestors(self.graph, anc):
                if n in self.smods.keys():
                    for sanc in self.smods[n]:
                        sobj = sanc.replace(".anc", ".o")
                        if not self.graph.has_edge(sobj, program):
                            self.graph.add_edge(sobj, program)
                            debug_msg += f"\n  \u251C\u2500\u2500\u2500\u2500 link submodule object {sobj} to program"
                if self.graph.nodes[n]["type"] != "anc":
                    continue
                debug_msg += f"\n  \u251C\u2500\u2500\u2500\u2500 add ancestor {n.replace('.anc', '.o')}"
                self.graph.add_edge(n.replace(".anc", ".o"), program)

            # Add c objects
            for n in self.graph.nodes:
                if self.graph.nodes[n]["type"] != "cobj":
                    continue
                debug_msg += f"\n  \u251C\u2500\u2500\u2500\u2500 add c object {n}"
                self.graph.add_edge(n, program)

            self.renew_status(program)
            self.sync_targets()

        if f90.library:
            library = f90.library if f90.library.endswith(".a") else f90.library + ".a"

            self.graph.add_node(
                library,
                type="tar",
                library=True,
                status=-1,
            )
            logger.info(f"Add target {library}")
            self.graph.add_edge(obj, library)

            debug_msg += f"\n  \u251C\u2500\u2500 add new program {library}"

            self.renew_status(program)
            self.sync_targets()

        debug_msg += "\n  \u2514\u2500\u2500 finished"
        logger.debug(debug_msg)

    def write(self) -> None:
        """Creates a serialized form of the dependency graph which can be saved."""
        with open(os.path.join(config.build_dir, self.fname), "w") as file:
            self.graph.graph["status"] = self.status
            json.dump(nx.node_link_data(self.graph), file)

    def draw(self) -> None:
        """Draws the current dependency graph with matplotlib"""

        def calc_layer(node: str) -> None:
            if "layer" in self.graph.nodes[node]:
                return

            static_layers = {
                "src": 1,
                "inc": 2,
                "f90": 4,
                "req": 5,
                "obj": 199,
                "tar": 200,
                "c": 4,
                "cobj": 199,
            }
            type = self.graph.nodes[node]["type"]
            if type in static_layers:
                self.graph.nodes[node]["layer"] = static_layers[type]
                return

            mlayer = 6
            for pred in self.graph.predecessors(node):
                if "layer" not in self.graph.nodes[pred]:
                    calc_layer(pred)
                mlayer = max(mlayer, self.graph.nodes[pred]["layer"])
            self.graph.nodes[node]["layer"] = mlayer + 1

        for n in self.graph.nodes:
            if "layer" in self.graph.nodes[n]:
                del self.graph.nodes[n]["layer"]
        for n in self.graph.nodes:
            calc_layer(n)

        pos = nx.multipartite_layout(self.graph, subset_key="layer", align="horizontal")

        nodecolors = {
            "tar": "black",
            "obj": "darkorchid",
            "smod": "lightcoral",
            "mod": "firebrick",
            "anc": "darkorange",
            "req": "fuchsia",
            "f90": "navy",
            "c": "skyblue",
            "cobj": "blueviolet",
            "inc": "darkgreen",
            "src": "limegreen",
        }

        # Draw nodes, differentiate valid/invalid
        for type in nodecolors:
            nx.draw_networkx_nodes(
                self.graph,
                pos,
                nodelist=[
                    n
                    for n, data in self.graph.nodes(data=True)
                    if data["type"] == type and data["status"] < STATUS_CHECK
                ],
                node_size=1000,
                node_color="white",
                node_shape="o",
                edgecolors=nodecolors[type],
            )
            nx.draw_networkx_nodes(
                self.graph,
                pos,
                nodelist=[
                    n
                    for n, data in self.graph.nodes(data=True)
                    if data["type"] == type and data["status"] == STATUS_CHECK
                ],
                node_size=1000,
                node_shape="s",
                node_color=nodecolors[type],
            )
            nx.draw_networkx_nodes(
                self.graph,
                pos,
                nodelist=[
                    n
                    for n, data in self.graph.nodes(data=True)
                    if data["type"] == type and data["status"] == STATUS_BUILT
                ],
                node_size=1000,
                node_shape="o",
                node_color=nodecolors[type],
            )

        nx.draw_networkx_edges(
            self.graph,
            pos,
            node_size=1000,
            arrows=True,
            arrowstyle="->",
            edge_color="gray",
            width=2,
        )
        nx.draw_networkx_labels(
            self.graph, pos, font_size=10, bbox={"ec": "k", "fc": "white", "alpha": 0.7}
        )

        plt.tight_layout()
        plt.show()

        return


logger: logging.Logger
config: Configuration

if __name__ == "__main__":
    make()
